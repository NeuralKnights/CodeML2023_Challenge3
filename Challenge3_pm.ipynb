{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Librairies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Data Modeling\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, f1_score, accuracy_score\n",
    "import xgboost as xgb\n",
    "from aequitas.group import Group\n",
    "from aequitas.bias import Bias\n",
    "from aequitas.fairness import Fairness\n",
    "# Data Vizualization Librairies\n",
    "import seaborn as sns\n",
    "\n",
    "# Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fonctions utilitaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAgeCat(age: int) -> str:\n",
    "    cat: str = \"\"\n",
    "\n",
    "    if(age < 35):\n",
    "        cat = \"34 & -\"\n",
    "    elif (age >=35 and age < 45):\n",
    "        cat = \"35-44\"\n",
    "    elif (age >= 45 and age < 55):\n",
    "        cat = \"45-54\"\n",
    "    elif (age >= 55 and age < 65):\n",
    "        cat = \"55-64\"\n",
    "    else:\n",
    "        cat = \"65 & +\"\n",
    "\n",
    "    return cat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_0</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>PAY_5</th>\n",
       "      <th>PAY_6</th>\n",
       "      <th>BILL_AMT1</th>\n",
       "      <th>...</th>\n",
       "      <th>BILL_AMT4</th>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "      <th>default-payment-next-month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>3.000000e+04</td>\n",
       "      <td>30000.00000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>30000.000000</td>\n",
       "      <td>24000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>15000.500000</td>\n",
       "      <td>167484.322667</td>\n",
       "      <td>35.485500</td>\n",
       "      <td>-0.016700</td>\n",
       "      <td>-0.133767</td>\n",
       "      <td>-0.166200</td>\n",
       "      <td>-0.220667</td>\n",
       "      <td>-0.266200</td>\n",
       "      <td>-0.291100</td>\n",
       "      <td>51223.330900</td>\n",
       "      <td>...</td>\n",
       "      <td>43262.948967</td>\n",
       "      <td>40311.400967</td>\n",
       "      <td>38871.760400</td>\n",
       "      <td>5663.580500</td>\n",
       "      <td>5.921163e+03</td>\n",
       "      <td>5225.68150</td>\n",
       "      <td>4826.076867</td>\n",
       "      <td>4799.387633</td>\n",
       "      <td>5215.502567</td>\n",
       "      <td>0.252333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8660.398374</td>\n",
       "      <td>129747.661567</td>\n",
       "      <td>9.217904</td>\n",
       "      <td>1.123802</td>\n",
       "      <td>1.197186</td>\n",
       "      <td>1.196868</td>\n",
       "      <td>1.169139</td>\n",
       "      <td>1.133187</td>\n",
       "      <td>1.149988</td>\n",
       "      <td>73635.860576</td>\n",
       "      <td>...</td>\n",
       "      <td>64332.856134</td>\n",
       "      <td>60797.155770</td>\n",
       "      <td>59554.107537</td>\n",
       "      <td>16563.280354</td>\n",
       "      <td>2.304087e+04</td>\n",
       "      <td>17606.96147</td>\n",
       "      <td>15666.159744</td>\n",
       "      <td>15278.305679</td>\n",
       "      <td>17777.465775</td>\n",
       "      <td>0.434361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-2.000000</td>\n",
       "      <td>-165580.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-170000.000000</td>\n",
       "      <td>-81334.000000</td>\n",
       "      <td>-339603.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7500.750000</td>\n",
       "      <td>50000.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>3558.750000</td>\n",
       "      <td>...</td>\n",
       "      <td>2326.750000</td>\n",
       "      <td>1763.000000</td>\n",
       "      <td>1256.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>8.330000e+02</td>\n",
       "      <td>390.00000</td>\n",
       "      <td>296.000000</td>\n",
       "      <td>252.500000</td>\n",
       "      <td>117.750000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>15000.500000</td>\n",
       "      <td>140000.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>22381.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>19052.000000</td>\n",
       "      <td>18104.500000</td>\n",
       "      <td>17071.000000</td>\n",
       "      <td>2100.000000</td>\n",
       "      <td>2.009000e+03</td>\n",
       "      <td>1800.00000</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>1500.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>22500.250000</td>\n",
       "      <td>240000.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>67091.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>54506.000000</td>\n",
       "      <td>50190.500000</td>\n",
       "      <td>49198.250000</td>\n",
       "      <td>5006.000000</td>\n",
       "      <td>5.000000e+03</td>\n",
       "      <td>4505.00000</td>\n",
       "      <td>4013.250000</td>\n",
       "      <td>4031.500000</td>\n",
       "      <td>4000.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>30000.000000</td>\n",
       "      <td>1000000.000000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>964511.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>891586.000000</td>\n",
       "      <td>927171.000000</td>\n",
       "      <td>961664.000000</td>\n",
       "      <td>873552.000000</td>\n",
       "      <td>1.684259e+06</td>\n",
       "      <td>896040.00000</td>\n",
       "      <td>621000.000000</td>\n",
       "      <td>426529.000000</td>\n",
       "      <td>528666.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 ID       LIMIT_BAL           AGE         PAY_0         PAY_2  \\\n",
       "count  30000.000000    30000.000000  30000.000000  30000.000000  30000.000000   \n",
       "mean   15000.500000   167484.322667     35.485500     -0.016700     -0.133767   \n",
       "std     8660.398374   129747.661567      9.217904      1.123802      1.197186   \n",
       "min        1.000000    10000.000000     21.000000     -2.000000     -2.000000   \n",
       "25%     7500.750000    50000.000000     28.000000     -1.000000     -1.000000   \n",
       "50%    15000.500000   140000.000000     34.000000      0.000000      0.000000   \n",
       "75%    22500.250000   240000.000000     41.000000      0.000000      0.000000   \n",
       "max    30000.000000  1000000.000000     79.000000      8.000000      8.000000   \n",
       "\n",
       "              PAY_3         PAY_4         PAY_5         PAY_6      BILL_AMT1  \\\n",
       "count  30000.000000  30000.000000  30000.000000  30000.000000   30000.000000   \n",
       "mean      -0.166200     -0.220667     -0.266200     -0.291100   51223.330900   \n",
       "std        1.196868      1.169139      1.133187      1.149988   73635.860576   \n",
       "min       -2.000000     -2.000000     -2.000000     -2.000000 -165580.000000   \n",
       "25%       -1.000000     -1.000000     -1.000000     -1.000000    3558.750000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000   22381.500000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000   67091.000000   \n",
       "max        8.000000      8.000000      8.000000      8.000000  964511.000000   \n",
       "\n",
       "       ...      BILL_AMT4      BILL_AMT5      BILL_AMT6       PAY_AMT1  \\\n",
       "count  ...   30000.000000   30000.000000   30000.000000   30000.000000   \n",
       "mean   ...   43262.948967   40311.400967   38871.760400    5663.580500   \n",
       "std    ...   64332.856134   60797.155770   59554.107537   16563.280354   \n",
       "min    ... -170000.000000  -81334.000000 -339603.000000       0.000000   \n",
       "25%    ...    2326.750000    1763.000000    1256.000000    1000.000000   \n",
       "50%    ...   19052.000000   18104.500000   17071.000000    2100.000000   \n",
       "75%    ...   54506.000000   50190.500000   49198.250000    5006.000000   \n",
       "max    ...  891586.000000  927171.000000  961664.000000  873552.000000   \n",
       "\n",
       "           PAY_AMT2      PAY_AMT3       PAY_AMT4       PAY_AMT5  \\\n",
       "count  3.000000e+04   30000.00000   30000.000000   30000.000000   \n",
       "mean   5.921163e+03    5225.68150    4826.076867    4799.387633   \n",
       "std    2.304087e+04   17606.96147   15666.159744   15278.305679   \n",
       "min    0.000000e+00       0.00000       0.000000       0.000000   \n",
       "25%    8.330000e+02     390.00000     296.000000     252.500000   \n",
       "50%    2.009000e+03    1800.00000    1500.000000    1500.000000   \n",
       "75%    5.000000e+03    4505.00000    4013.250000    4031.500000   \n",
       "max    1.684259e+06  896040.00000  621000.000000  426529.000000   \n",
       "\n",
       "            PAY_AMT6  default-payment-next-month  \n",
       "count   30000.000000                24000.000000  \n",
       "mean     5215.502567                    0.252333  \n",
       "std     17777.465775                    0.434361  \n",
       "min         0.000000                    0.000000  \n",
       "25%       117.750000                    0.000000  \n",
       "50%      1500.000000                    0.000000  \n",
       "75%      4000.000000                    1.000000  \n",
       "max    528666.000000                    1.000000  \n",
       "\n",
       "[8 rows x 22 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./Data/data_participant.csv\", index_col=None)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create \"Remaining Amount\" Column\n",
    "df[\"RMN_AMT2\"] = df[\"BILL_AMT2\"] - df[\"PAY_AMT1\"]\n",
    "df[\"RMN_AMT3\"] = df[\"BILL_AMT3\"] - df[\"PAY_AMT2\"]\n",
    "df[\"RMN_AMT4\"] = df[\"BILL_AMT4\"] - df[\"PAY_AMT3\"]\n",
    "df[\"RMN_AMT5\"] = df[\"BILL_AMT5\"] - df[\"PAY_AMT4\"]\n",
    "df[\"RMN_AMT6\"] = df[\"BILL_AMT6\"] - df[\"PAY_AMT5\"]\n",
    "\n",
    "# Create \"Sufficient Payment\"\n",
    "df[\"SUFFICIENT_PAYMENT_AMT2\"] = np.where(df[\"RMN_AMT2\"] <= 0, 1, 0)\n",
    "df[\"SUFFICIENT_PAYMENT_AMT3\"] = np.where(df[\"RMN_AMT3\"] <= 0, 1, 0)\n",
    "df[\"SUFFICIENT_PAYMENT_AMT4\"] = np.where(df[\"RMN_AMT4\"] <= 0, 1, 0)\n",
    "df[\"SUFFICIENT_PAYMENT_AMT5\"] = np.where(df[\"RMN_AMT5\"] <= 0, 1, 0)\n",
    "df[\"SUFFICIENT_PAYMENT_AMT6\"] = np.where(df[\"RMN_AMT6\"] <= 0, 1, 0)\n",
    "\n",
    "# Add weight to most recent months\n",
    "df[\"SUFFICIENT_PAYMENT_AMT2\"] = df[\"SUFFICIENT_PAYMENT_AMT2\"]*1.4\n",
    "df[\"SUFFICIENT_PAYMENT_AMT3\"] = df[\"SUFFICIENT_PAYMENT_AMT3\"]*1.3\n",
    "df[\"SUFFICIENT_PAYMENT_AMT4\"] = df[\"SUFFICIENT_PAYMENT_AMT4\"]*1.2\n",
    "df[\"SUFFICIENT_PAYMENT_AMT5\"] = df[\"SUFFICIENT_PAYMENT_AMT5\"]*1.1\n",
    "df[\"SUFFICIENT_PAYMENT_AMT6\"] = df[\"SUFFICIENT_PAYMENT_AMT6\"]*1\n",
    "\n",
    "df.drop(['RMN_AMT2', 'RMN_AMT3', 'RMN_AMT4', 'RMN_AMT5', 'RMN_AMT6', 'AGE'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>30000</td>\n",
       "      <td>30000</td>\n",
       "      <td>30000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>female</td>\n",
       "      <td>university</td>\n",
       "      <td>single</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>18112</td>\n",
       "      <td>14030</td>\n",
       "      <td>15964</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           SEX   EDUCATION MARRIAGE\n",
       "count    30000       30000    30000\n",
       "unique       2           5        4\n",
       "top     female  university   single\n",
       "freq     18112       14030    15964"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(exclude=np.number) # Describe Categorical Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats = df.select_dtypes(exclude=np.number).columns.tolist()\n",
    "for cat in cats:\n",
    "    df[cat] = df[cat].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Target and Explicative Datasets\n",
    "df_training = df[(~df['default-payment-next-month'].isna())]\n",
    "df_prediction = df[(df['default-payment-next-month'].isna())]\n",
    "\n",
    "X, y = df_training.drop(['default-payment-next-month'], axis=1), df_training['default-payment-next-month']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Train and Test Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.rename(columns={'default-payment-next-month': 'score'})\n",
    "# Standard Sklearn Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=17)\n",
    "sensitive_train, sensitive_test = X_train[['SEX', 'MARRIAGE', 'EDUCATION']], X_test[['SEX', 'MARRIAGE', 'EDUCATION']]\n",
    "\n",
    "# XGBoost Matrix\n",
    "dtrain_reg = xgb.DMatrix(X_train, y_train, enable_categorical=True)\n",
    "dtest_reg = xgb.DMatrix(X_test, y_test, enable_categorical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Hyperparameters\n",
    "params = {\n",
    "    \"objective\": \"binary:logistic\",\n",
    "    # 'max_depth': 4,\n",
    "    'learning_rate': 0.1\n",
    "    # \"num_class\": 2\n",
    "    # \"tree_method\": \"gpu_hist\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining and Training Model\n",
    "n = 100\n",
    "model = xgb.train(\n",
    "    params=params,\n",
    "    dtrain=dtrain_reg,\n",
    "    num_boost_round=n,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.796\n",
      "0.4506283662477558\n",
      "RMSE of the base model: 0.393\n"
     ]
    }
   ],
   "source": [
    "# RMSE Validation\n",
    "preds = model.predict(dtest_reg)\n",
    "rmse = mean_squared_error(y_test, preds, squared=False)\n",
    "\n",
    "preds_xgb = np.where(preds < 0.5, 0, 1)\n",
    "print(accuracy_score(y_test, preds_xgb))\n",
    "print(f1_score(y_test, preds_xgb))\n",
    "\n",
    "print(f\"RMSE of the base model: {rmse:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_xgb = pd.Series(preds_xgb)\n",
    "y_test_di1 = pd.DataFrame(y_test)\n",
    "y_test_di1[\"pred\"] = preds_xgb.values\n",
    "df_out_group = pd.concat([X_test[['SEX', 'MARRIAGE', 'EDUCATION']], y_test_di1], axis=1)\n",
    "df_out_group.rename(columns={'pred': 'score', 'default-payment-next-month': 'label_value'}, inplace=True)\n",
    "\n",
    "df_out_bias = pd.concat([X_test, y_test_di1], axis=1)\n",
    "df_out_bias.rename(columns={'pred': 'score', 'default-payment-next-month': 'label_value'}, inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_disparity_predefined_group()\n",
      "Aggregate Normalized DI: 0.04\n"
     ]
    }
   ],
   "source": [
    "g = Group()\n",
    "\n",
    "df_out_group.dtypes\n",
    "df_out_group['SEX'] = df_out_group['SEX'].astype('str')\n",
    "df_out_group['MARRIAGE'] = df_out_group['MARRIAGE'].astype('str')\n",
    "df_out_group['EDUCATION'] = df_out_group['EDUCATION'].astype('str')\n",
    "xtab, _ = g.get_crosstabs(df_out_group)\n",
    "\n",
    "b = Bias()\n",
    "\n",
    "# Calculate DI\n",
    "ref_groups_dict = {\n",
    "    'SEX': 'female',\n",
    "    'SEX': 'male',\n",
    "    'MARRIAGE': 'married',\n",
    "    'MARRIAGE': 'others',\n",
    "    'MARRIAGE': 'single',\n",
    "    'MARRIAGE': 'unknown',\n",
    "    'EDUCATION': 'graduate school',\n",
    "    'EDUCATION': 'high school',\n",
    "    'EDUCATION': 'others',\n",
    "    'EDUCATION': 'university',\n",
    "    'EDUCATION': 'unknown',\n",
    "}\n",
    "\n",
    "bdf1 = b.get_disparity_predefined_groups(xtab, original_df=df_out_group, ref_groups_dict=ref_groups_dict)\n",
    "\n",
    "# Calculate Disparate Impact (DI) manually and create a custom column\n",
    "bdf1['disparity_index'] = 1 - abs(bdf1['fpr'] - 1)\n",
    "bdf1['weight_adjustment'] = 1 - bdf1['disparity_index']\n",
    "\n",
    "# Define the sensitive attribute categories\n",
    "# Calculate the aggregate Normalized DI (simple average)\n",
    "aggregate_normalized_di = bdf1['disparity_index'].sum() / len(bdf1['disparity_index'])\n",
    "\n",
    "# Print the aggregate Normalized DI\n",
    "print(f'Aggregate Normalized DI: {aggregate_normalized_di:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distributing Weight in Dataset\n",
    "X2 = X.copy()\n",
    "\n",
    "X2['sex_weight'] = ''\n",
    "w = bdf1.query('attribute_name == \"SEX\" and attribute_value == \"female\"')['weight_adjustment'].values[0]\n",
    "X2['sex_weight'] = np.where(X2['SEX'] == \"female\", w, X2['sex_weight'])\n",
    "w = bdf1.query('attribute_name == \"SEX\" and attribute_value == \"male\"')['weight_adjustment'].values[0]\n",
    "X2['sex_weight'] = np.where(X2['SEX'] == \"male\", w, X2['sex_weight'])\n",
    "\n",
    "X2['education_weight'] = ''\n",
    "w = bdf1.query('attribute_name == \"EDUCATION\" and attribute_value == \"graduate school\"')['weight_adjustment'].values[0]\n",
    "X2['education_weight'] = np.where(X2['EDUCATION'] == \"graduate school\", w, X2['education_weight'])\n",
    "w = bdf1.query('attribute_name == \"EDUCATION\" and attribute_value == \"high school\"')['weight_adjustment'].values[0]\n",
    "X2['education_weight'] = np.where(X2['EDUCATION'] == \"high school\", w, X2['education_weight'])\n",
    "X2['education_weight'] = np.where(X2['EDUCATION'] == \"graduate school\", w, X2['education_weight'])\n",
    "w = bdf1.query('attribute_name == \"EDUCATION\" and attribute_value == \"others\"')['weight_adjustment'].values[0]\n",
    "X2['education_weight'] = np.where(X2['EDUCATION'] == \"others\", w, X2['education_weight'])\n",
    "w = bdf1.query('attribute_name == \"EDUCATION\" and attribute_value == \"university\"')['weight_adjustment'].values[0]\n",
    "X2['education_weight'] = np.where(X2['EDUCATION'] == \"university\", w, X2['education_weight'])\n",
    "w = bdf1.query('attribute_name == \"EDUCATION\" and attribute_value == \"unknown\"')['weight_adjustment'].values[0]\n",
    "X2['education_weight'] = np.where(X2['EDUCATION'] == \"unknown\", w, X2['education_weight'])\n",
    "\n",
    "X2['marriage_weight'] = ''\n",
    "w = bdf1.query('attribute_name == \"MARRIAGE\" and attribute_value == \"married\"')['weight_adjustment'].values[0]\n",
    "X2['marriage_weight'] = np.where(X2['MARRIAGE'] == \"married\", w, X2['marriage_weight'])\n",
    "w = bdf1.query('attribute_name == \"MARRIAGE\" and attribute_value == \"single\"')['weight_adjustment'].values[0]\n",
    "X2['marriage_weight'] = np.where(X2['MARRIAGE'] == \"single\", w, X2['marriage_weight'])\n",
    "w = bdf1.query('attribute_name == \"MARRIAGE\" and attribute_value == \"others\"')['weight_adjustment'].values[0]\n",
    "X2['marriage_weight'] = np.where(X2['MARRIAGE'] == \"others\", w, X2['marriage_weight'])\n",
    "w = bdf1.query('attribute_name == \"MARRIAGE\" and attribute_value == \"unknown\"')['weight_adjustment'].values[0]\n",
    "X2['marriage_weight'] = np.where(X2['MARRIAGE'] == \"unknown\", w, X2['marriage_weight'])\n",
    "\n",
    "X2['composite_weight'] = X2['sex_weight'] * X2['education_weight'] * X2['marriage_weight']\n",
    "X2.drop(['sex_weight', 'education_weight', 'marriage_weight'], axis=1, inplace=True)\n",
    "X2['composite_weight'] = X2['composite_weight'].astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2, y, random_state=17)\n",
    "sensitive_train2, sensitive_test2 = X_train2[['SEX', 'MARRIAGE', 'EDUCATION']], X_test2[['SEX', 'MARRIAGE', 'EDUCATION']]\n",
    "weight_train = X_train2['composite_weight']\n",
    "weight_test = X_test2['composite_weight']\n",
    "X_train2.drop('composite_weight', axis=1, inplace=True)\n",
    "X_test2.drop('composite_weight', axis=1, inplace=True)\n",
    "\n",
    "\n",
    "# XGBoost Matrix\n",
    "dtrain_reg2 = xgb.DMatrix(X_train2, y_train2, enable_categorical=True, weight=weight_train)\n",
    "dtest_reg2 = xgb.DMatrix(X_test2, y_test2, enable_categorical=True, weight=weight_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Hyperparameters\n",
    "params = {\n",
    "    'Objective': 'reg:tweedie',\n",
    "    # 'max_depth': 4,\n",
    "    'learning_rate': 0.1,\n",
    "    \"num_class\": 2\n",
    "    # \"tree_method\": \"gpu_hist\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining and Training Model\n",
    "n = 100\n",
    "model2 = xgb.train(\n",
    "    params=params,\n",
    "    dtrain=dtrain_reg2,\n",
    "    num_boost_round=n\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7928333333333333\n",
      "0.44484144707458695\n",
      "RMSE of the base model: 0.455\n"
     ]
    }
   ],
   "source": [
    "# RMSE Validation\n",
    "preds = model2.predict(dtest_reg2)\n",
    "rmse = mean_squared_error(y_test2, preds, squared=False)\n",
    "\n",
    "preds_xgb = np.where(preds < 0.5, 0, 1)\n",
    "print(accuracy_score(y_test2, preds_xgb))\n",
    "print(f1_score(y_test2, preds_xgb))\n",
    "\n",
    "print(f\"RMSE of the base model: {rmse:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_disparity_predefined_group()\n",
      "Aggregate Normalized DI: 0.04\n",
      "Aggregate Normalized DI: 0.04\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "preds_xgb = pd.Series(preds_xgb)\n",
    "y_test_di1 = pd.DataFrame(y_test2)\n",
    "y_test_di1[\"pred\"] = preds_xgb.values\n",
    "df_out_group = pd.concat([X_test2[['SEX', 'MARRIAGE', 'EDUCATION']], y_test_di1], axis=1)\n",
    "df_out_group.rename(columns={'pred': 'score', 'default-payment-next-month': 'label_value'}, inplace=True)\n",
    "\n",
    "df_out_bias = pd.concat([X_test2, y_test_di1], axis=1)\n",
    "df_out_bias.rename(columns={'pred': 'score', 'default-payment-next-month': 'label_value'}, inplace=True) \n",
    "\n",
    "g = Group()\n",
    "\n",
    "df_out_group.dtypes\n",
    "df_out_group['SEX'] = df_out_group['SEX'].astype('str')\n",
    "df_out_group['MARRIAGE'] = df_out_group['MARRIAGE'].astype('str')\n",
    "df_out_group['EDUCATION'] = df_out_group['EDUCATION'].astype('str')\n",
    "xtab, _ = g.get_crosstabs(df_out_group)\n",
    "\n",
    "b = Bias()\n",
    "\n",
    "# Calculate DI\n",
    "ref_groups_dict = {\n",
    "    'SEX': 'female',\n",
    "    'SEX': 'male',\n",
    "    'MARRIAGE': 'married',\n",
    "    'MARRIAGE': 'others',\n",
    "    'MARRIAGE': 'single',\n",
    "    'MARRIAGE': 'unknown',\n",
    "    'EDUCATION': 'graduate school',\n",
    "    'EDUCATION': 'high school',\n",
    "    'EDUCATION': 'others',\n",
    "    'EDUCATION': 'university',\n",
    "    'EDUCATION': 'unknown',\n",
    "}\n",
    "\n",
    "bdf2 = b.get_disparity_predefined_groups(xtab, original_df=df_out_group, ref_groups_dict=ref_groups_dict)\n",
    "\n",
    "# Calculate Disparate Impact (DI) manually and create a custom column\n",
    "bdf2['disparity_index'] = 1 - abs(bdf1['fpr'] - 1)\n",
    "bdf2['weight_adjustment'] = 1 - bdf1['disparity_index']\n",
    "\n",
    "# Define the sensitive attribute categories\n",
    "# Calculate the aggregate Normalized DI (simple average)\n",
    "aggregate_normalized_di2 = bdf2['disparity_index'].sum() / len(bdf1['disparity_index'])\n",
    "\n",
    "# Print the aggregate Normalized DI\n",
    "\n",
    "print(f'Aggregate Normalized DI: {aggregate_normalized_di:.2f}')\n",
    "print(f'Aggregate Normalized DI: {aggregate_normalized_di2:.2f}')\n",
    "print(aggregate_normalized_di / aggregate_normalized_di2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_final = df_prediction.drop('default-payment-next-month', axis=1)\n",
    "dfinal_reg = xgb.DMatrix(X_final, enable_categorical=True)\n",
    "final = model2.predict(dfinal_reg)\n",
    "\n",
    "final = np.where(final < 0.5, 0, 1)\n",
    "final = pd.DataFrame(final)\n",
    "\n",
    "\n",
    "\n",
    "final.to_csv('./Data/final.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "codeml2023",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
